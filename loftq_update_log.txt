Comment updated to: We support LoftQ
Run at: 2025-12-18T02:47:41
Root: C:\Users\HZ\Documents\Dev\unsloth\notebooks

nb\bert_classification.ipynb:191
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\CodeForces-cot-Finetune_for_Reasoning_on_CodeForces.ipynb:257
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\CodeGemma_(7B)-Conversational.ipynb:157
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Deepseek_OCR_(3B)-Eval.ipynb:545
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Deepseek_OCR_(3B)-Evaluation.ipynb:698
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Deepseek_OCR_(3B).ipynb:545
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\ERNIE_4_5_21B_A3B_PT-Conversational.ipynb:622
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Gemma2_(2B)-Alpaca.ipynb:318
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Gemma2_(9B)-Alpaca.ipynb:347
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Gemma3N_(4B)-Audio.ipynb:420
- '    "    loftq_config = None,               # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Gemma3N_(4B)-Vision.ipynb:478
- '    "    loftq_config = None,               # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Gemma3_(270M).ipynb:368
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Gemma3_(4B)-Vision-GRPO.ipynb:452
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Gemma3_(4B)-Vision.ipynb:400
- '    "    loftq_config = None,               # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\gpt-oss-(120B)_A100-Fine-tuning.ipynb:767
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\gpt-oss-(20B)-Fine-tuning.ipynb:444
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\gpt-oss-(20B)_A100-GRPO.ipynb:767
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\gpt_oss_(20B)_500K_Context_Fine_tuning.ipynb:479
- '        "    loftq_config = None, # And LoftQ\\n",'
+ '        "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Granite4.0.ipynb:200
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Granite4.0_350M.ipynb:370
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\HuggingFace Course-Gemma3_(4B)-Vision-GRPO.ipynb:454
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\HuggingFace Course-gpt-oss-(20B)_A100-GRPO.ipynb:769
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\HuggingFace Course-Qwen2_5_7B_VL_GRPO.ipynb:623
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\HuggingFace Course-Qwen3_VL_(8B)-Vision-GRPO.ipynb:562
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-bert_classification.ipynb:191
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-CodeForces-cot-Finetune_for_Reasoning_on_CodeForces.ipynb:257
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-CodeGemma_(7B)-Conversational.ipynb:157
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Deepseek_OCR_(3B)-Eval.ipynb:545
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Deepseek_OCR_(3B)-Evaluation.ipynb:698
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Deepseek_OCR_(3B).ipynb:545
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-ERNIE_4_5_21B_A3B_PT-Conversational.ipynb:622
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Gemma2_(2B)-Alpaca.ipynb:318
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Gemma2_(9B)-Alpaca.ipynb:347
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Gemma3N_(4B)-Audio.ipynb:420
- '    "    loftq_config = None,               # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Gemma3N_(4B)-Vision.ipynb:478
- '    "    loftq_config = None,               # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Gemma3_(270M).ipynb:368
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Gemma3_(4B)-Vision-GRPO.ipynb:445
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Gemma3_(4B)-Vision.ipynb:400
- '    "    loftq_config = None,               # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-gpt-oss-(120B)_A100-Fine-tuning.ipynb:767
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-gpt-oss-(20B)-Fine-tuning.ipynb:444
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-gpt-oss-(20B)_A100-GRPO.ipynb:767
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-gpt_oss_(20B)_500K_Context_Fine_tuning.ipynb:444
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Granite4.0.ipynb:200
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Granite4.0_350M.ipynb:370
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Llama3.1_(8B)-Alpaca.ipynb:289
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Llama3.2_(11B)-Vision.ipynb:428
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Llama3.2_(1B)-RAFT.ipynb:650
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Llama3.2_(1B_and_3B)-Conversational.ipynb:146
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Llama3.3_(70B)_A100-Conversational.ipynb:545
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Llama3_(8B)-Alpaca.ipynb:324
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Llama3_(8B)-Conversational.ipynb:323
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Llama3_(8B)-Ollama.ipynb:286
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Llama3_(8B)-ORPO.ipynb:323
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Llasa_TTS_(1B).ipynb:213
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Llasa_TTS_(3B).ipynb:205
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Magistral_(24B)-Reasoning-Conversational.ipynb:413
- '    "    loftq_config = None,  # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Meta-Synthetic-Data-Llama3.1_(8B).ipynb:807
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Meta_Synthetic_Data_Llama3_2_(3B).ipynb:887
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Ministral_3_VL_(3B)_Vision.ipynb:447
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Mistral_(7B)-Text_Completion.ipynb:385
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Mistral_Nemo_(12B)-Alpaca.ipynb:470
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Mistral_Small_(22B)-Alpaca.ipynb:439
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Mistral_v0.3_(7B)-Alpaca.ipynb:356
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Mistral_v0.3_(7B)-Conversational.ipynb:348
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Mistral_v0.3_(7B)-CPT.ipynb:141
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Nemotron-3-Nano-30B-A3B_A100.ipynb:737
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Nemotron-Nano-3-30B-A3B_A100.ipynb:737
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Orpheus_(3B)-TTS.ipynb:167
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Oute_TTS_(1B).ipynb:185
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Phi_3.5_Mini-Conversational.ipynb:339
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Phi_3_Medium-Conversational.ipynb:483
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Phi_4-Conversational.ipynb:461
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Pixtral_(12B)-Vision.ipynb:454
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Qwen2.5_(7B)-Alpaca.ipynb:368
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Qwen2.5_Coder_(14B)-Conversational.ipynb:471
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Qwen2.5_VL_(7B)-Vision.ipynb:412
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Qwen2_(7B)-Alpaca.ipynb:402
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Qwen2_5_7B_VL_GRPO.ipynb:614
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Qwen2_VL_(7B)-Vision.ipynb:410
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Qwen3_(14B)-Alpaca.ipynb:530
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Qwen3_(14B)-Reasoning-Conversational.ipynb:489
- '    "    loftq_config = None,  # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Qwen3_(14B).ipynb:489
- '    "    loftq_config = None,  # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Qwen3_(32B)_A100-Reasoning-Conversational.ipynb:537
- '    "    loftq_config = None,  # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Qwen3_(4B)-Instruct.ipynb:465
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Qwen3_(4B)-Thinking.ipynb:465
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Qwen3_(4B)_Instruct-QAT.ipynb:486
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Qwen3_VL_(8B)-Vision-GRPO.ipynb:553
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Qwen3_VL_(8B)-Vision.ipynb:186
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Sesame_CSM_(1B)-TTS.ipynb:148
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Spark_TTS_(0_5B).ipynb:188
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-TinyLlama_(1.1B)-Alpaca.ipynb:358
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Whisper.ipynb:400
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Kaggle-Zephyr_(7B)-DPO.ipynb:1040
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Llama3.1_(8B)-Alpaca.ipynb:289
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Llama3.2_(11B)-Vision.ipynb:428
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Llama3.2_(1B)-RAFT.ipynb:650
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Llama3.2_(1B_and_3B)-Conversational.ipynb:146
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Llama3.3_(70B)_A100-Conversational.ipynb:545
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Llama3_(8B)-Alpaca.ipynb:324
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Llama3_(8B)-Conversational.ipynb:323
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Llama3_(8B)-Ollama.ipynb:286
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Llama3_(8B)-ORPO.ipynb:323
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Llasa_TTS_(1B).ipynb:213
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Llasa_TTS_(3B).ipynb:205
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Magistral_(24B)-Reasoning-Conversational.ipynb:413
- '    "    loftq_config = None,  # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Meta-Synthetic-Data-Llama3.1_(8B).ipynb:821
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Meta_Synthetic_Data_Llama3_2_(3B).ipynb:901
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Ministral_3_VL_(3B)_Vision.ipynb:482
- '        "    loftq_config = None, # And LoftQ\\n",'
+ '        "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Mistral_(7B)-Text_Completion.ipynb:385
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Mistral_Nemo_(12B)-Alpaca.ipynb:470
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Mistral_Small_(22B)-Alpaca.ipynb:439
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Mistral_v0.3_(7B)-Alpaca.ipynb:356
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Mistral_v0.3_(7B)-Conversational.ipynb:348
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Mistral_v0.3_(7B)-CPT.ipynb:141
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Nemotron-3-Nano-30B-A3B_A100.ipynb:737
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Nemotron-Nano-3-30B-A3B_A100.ipynb:737
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Orpheus_(3B)-TTS.ipynb:167
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Oute_TTS_(1B).ipynb:185
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Phi_3.5_Mini-Conversational.ipynb:339
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Phi_3_Medium-Conversational.ipynb:483
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Phi_4-Conversational.ipynb:461
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Pixtral_(12B)-Vision.ipynb:454
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Qwen2.5_(7B)-Alpaca.ipynb:368
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Qwen2.5_Coder_(14B)-Conversational.ipynb:471
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Qwen2.5_VL_(7B)-Vision.ipynb:412
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Qwen2_(7B)-Alpaca.ipynb:402
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Qwen2_5_7B_VL_GRPO.ipynb:621
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Qwen2_VL_(7B)-Vision.ipynb:410
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Qwen3_(14B)-Alpaca.ipynb:530
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Qwen3_(14B)-Reasoning-Conversational.ipynb:489
- '    "    loftq_config = None,  # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Qwen3_(14B).ipynb:489
- '    "    loftq_config = None,  # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Qwen3_(32B)_A100-Reasoning-Conversational.ipynb:537
- '    "    loftq_config = None,  # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Qwen3_(4B)-Instruct.ipynb:465
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Qwen3_(4B)-Thinking.ipynb:465
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Qwen3_(4B)_Instruct-QAT.ipynb:486
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Qwen3_VL_(8B)-Vision-GRPO.ipynb:553
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Qwen3_VL_(8B)-Vision.ipynb:186
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Sesame_CSM_(1B)-TTS.ipynb:148
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Spark_TTS_(0_5B).ipynb:188
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Synthetic_Data_Hackathon.ipynb:309
- '    "    loftq_config=None,\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: <none>
  comment_after: # We support LoftQ

nb\TinyLlama_(1.1B)-Alpaca.ipynb:358
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Whisper.ipynb:400
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

nb\Zephyr_(7B)-DPO.ipynb:1040
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\bert_classification.ipynb:168
- '        "    loftq_config = None, # And LoftQ\\n",'
+ '        "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\CodeForces-cot-Finetune_for_Reasoning_on_CodeForces.ipynb:232
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\CodeGemma_(7B)-Conversational.ipynb:134
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Deepseek_OCR_(3B)-Eval.ipynb:522
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Deepseek_OCR_(3B)-Evaluation.ipynb:675
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Deepseek_OCR_(3B).ipynb:522
- '        "    loftq_config = None, # And LoftQ\\n",'
+ '        "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\ERNIE_4_5_21B_A3B_PT-Conversational.ipynb:599
- '        "    loftq_config = None, # And LoftQ\\n",'
+ '        "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Gemma2_(2B)-Alpaca.ipynb:295
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Gemma2_(9B)-Alpaca.ipynb:324
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Gemma3N_(4B)-Audio.ipynb:397
- '    "    loftq_config = None,               # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Gemma3N_(4B)-Vision.ipynb:455
- '        "    loftq_config = None,               # And LoftQ\\n",'
+ '        "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Gemma3_(270M).ipynb:345
- '        "    loftq_config = None, # And LoftQ\\n",'
+ '        "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Gemma3_(4B)-Vision-GRPO.ipynb:431
- '        "    loftq_config = None, # And LoftQ\\n",'
+ '        "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Gemma3_(4B)-Vision.ipynb:377
- '    "    loftq_config = None,               # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\gpt-oss-(120B)_A100-Fine-tuning.ipynb:744
- '        "    loftq_config = None, # And LoftQ\\n",'
+ '        "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\gpt-oss-(20B)-Fine-tuning.ipynb:421
- '        "    loftq_config = None, # And LoftQ\\n",'
+ '        "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\gpt-oss-(20B)_A100-GRPO.ipynb:744
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\gpt_oss_(20B)_500K_Context_Fine_tuning.ipynb:421
- '        "    loftq_config = None, # And LoftQ\\n",'
+ '        "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Granite4.0.ipynb:177
- '        "    loftq_config = None, # And LoftQ\\n",'
+ '        "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Granite4.0_350M.ipynb:359
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Llama3.1_(8B)-Alpaca.ipynb:266
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Llama3.2_(11B)-Vision.ipynb:405
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Llama3.2_(1B)-RAFT.ipynb:627
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Llama3.2_(1B_and_3B)-Conversational.ipynb:123
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Llama3.3_(70B)_A100-Conversational.ipynb:522
- '        "    loftq_config = None, # And LoftQ\\n",'
+ '        "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Llama3_(8B)-Alpaca.ipynb:301
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Llama3_(8B)-Conversational.ipynb:300
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Llama3_(8B)-Ollama.ipynb:263
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Llama3_(8B)-ORPO.ipynb:300
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Llasa_TTS_(1B).ipynb:190
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Llasa_TTS_(3B).ipynb:182
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Magistral_(24B)-Reasoning-Conversational.ipynb:390
- '        "    loftq_config = None,  # And LoftQ\\n",'
+ '        "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Meta-Synthetic-Data-Llama3.1_(8B).ipynb:798
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Meta_Synthetic_Data_Llama3_2_(3B).ipynb:878
- '        "    loftq_config = None, # And LoftQ\\n",'
+ '        "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Ministral_3_VL_(3B)_Vision.ipynb:424
- '        "    loftq_config = None, # And LoftQ\\n",'
+ '        "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Mistral_(7B)-Text_Completion.ipynb:362
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Mistral_Nemo_(12B)-Alpaca.ipynb:447
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Mistral_Small_(22B)-Alpaca.ipynb:416
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Mistral_v0.3_(7B)-Alpaca.ipynb:333
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Mistral_v0.3_(7B)-Conversational.ipynb:325
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Mistral_v0.3_(7B)-CPT.ipynb:118
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Nemotron-3-Nano-30B-A3B_A100.ipynb:737
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Nemotron-Nano-3-30B-A3B_A100.ipynb:737
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Orpheus_(3B)-TTS.ipynb:144
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Oute_TTS_(1B).ipynb:199
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Phi_3.5_Mini-Conversational.ipynb:316
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Phi_3_Medium-Conversational.ipynb:460
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Phi_4-Conversational.ipynb:438
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Pixtral_(12B)-Vision.ipynb:431
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Qwen2.5_(7B)-Alpaca.ipynb:345
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Qwen2.5_Coder_(14B)-Conversational.ipynb:448
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Qwen2.5_VL_(7B)-Vision.ipynb:389
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Qwen2_(7B)-Alpaca.ipynb:379
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Qwen2_5_7B_VL_GRPO.ipynb:600
- '        "    loftq_config = None, # And LoftQ\\n",'
+ '        "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Qwen2_VL_(7B)-Vision.ipynb:387
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Qwen3_(14B)-Alpaca.ipynb:507
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Qwen3_(14B)-Reasoning-Conversational.ipynb:466
- '        "    loftq_config = None,  # And LoftQ\\n",'
+ '        "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Qwen3_(14B).ipynb:466
- '        "    loftq_config = None,  # And LoftQ\\n",'
+ '        "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Qwen3_(32B)_A100-Reasoning-Conversational.ipynb:514
- '        "    loftq_config = None,  # And LoftQ\\n",'
+ '        "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Qwen3_(4B)-Instruct.ipynb:442
- '        "    loftq_config = None, # And LoftQ\\n",'
+ '        "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Qwen3_(4B)-Thinking.ipynb:442
- '        "    loftq_config = None, # And LoftQ\\n",'
+ '        "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Qwen3_(4B)_Instruct-QAT.ipynb:463
- '        "    loftq_config = None, # And LoftQ\\n",'
+ '        "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Qwen3_VL_(8B)-Vision-GRPO.ipynb:539
- '        "    loftq_config = None, # And LoftQ\\n",'
+ '        "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Qwen3_VL_(8B)-Vision.ipynb:163
- '        "    loftq_config = None, # And LoftQ\\n",'
+ '        "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Sesame_CSM_(1B)-TTS.ipynb:125
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Spark_TTS_(0_5B).ipynb:165
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\TinyLlama_(1.1B)-Alpaca.ipynb:335
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Whisper.ipynb:411
- '        "    loftq_config = None, # And LoftQ\\n",'
+ '        "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

original_template\Zephyr_(7B)-DPO.ipynb:1017
- '    "    loftq_config = None, # And LoftQ\\n",'
+ '    "    loftq_config = None,  # We support LoftQ\\n",'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\bert_classification.py:109
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\CodeForces-cot-Finetune_for_Reasoning_on_CodeForces.py:88
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\CodeGemma_(7B)-Conversational.py:89
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Deepseek_OCR_(3B)-Eval.py:151
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Deepseek_OCR_(3B)-Evaluation.py:278
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Deepseek_OCR_(3B).py:151
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\ERNIE_4_5_21B_A3B_PT-Conversational.py:89
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Gemma2_(2B)-Alpaca.py:95
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Gemma2_(9B)-Alpaca.py:94
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Gemma3N_(4B)-Audio.py:179
- '    loftq_config = None,               # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Gemma3N_(4B)-Vision.py:97
- '    loftq_config = None,               # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Gemma3_(270M).py:90
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Gemma3_(4B)-Vision-GRPO.py:113
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Gemma3_(4B)-Vision.py:91
- '    loftq_config = None,               # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\gpt-oss-(120B)_A100-Fine-tuning.py:85
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\gpt-oss-(20B)-Fine-tuning.py:85
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\gpt-oss-(20B)_A100-GRPO.py:85
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\gpt_oss_(20B)_500K_Context_Fine_tuning.py:88
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Granite4.0.py:93
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Granite4.0_350M.py:93
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\HuggingFace Course-Gemma3_(4B)-Vision-GRPO.py:115
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\HuggingFace Course-gpt-oss-(20B)_A100-GRPO.py:87
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\HuggingFace Course-Qwen2_5_7B_VL_GRPO.py:105
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\HuggingFace Course-Qwen3_VL_(8B)-Vision-GRPO.py:108
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-bert_classification.py:109
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-CodeForces-cot-Finetune_for_Reasoning_on_CodeForces.py:88
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-CodeGemma_(7B)-Conversational.py:89
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Deepseek_OCR_(3B)-Eval.py:151
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Deepseek_OCR_(3B)-Evaluation.py:278
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Deepseek_OCR_(3B).py:151
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-ERNIE_4_5_21B_A3B_PT-Conversational.py:89
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Gemma2_(2B)-Alpaca.py:95
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Gemma2_(9B)-Alpaca.py:94
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Gemma3N_(4B)-Audio.py:179
- '    loftq_config = None,               # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Gemma3N_(4B)-Vision.py:97
- '    loftq_config = None,               # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Gemma3_(270M).py:90
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Gemma3_(4B)-Vision-GRPO.py:91
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Gemma3_(4B)-Vision.py:91
- '    loftq_config = None,               # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-gpt-oss-(120B)_A100-Fine-tuning.py:85
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-gpt-oss-(20B)-Fine-tuning.py:85
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-gpt-oss-(20B)_A100-GRPO.py:85
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-gpt_oss_(20B)_500K_Context_Fine_tuning.py:86
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Granite4.0.py:93
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Granite4.0_350M.py:99
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Llama3.1_(8B)-Alpaca.py:91
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Llama3.2_(11B)-Vision.py:91
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Llama3.2_(1B)-RAFT.py:201
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Llama3.2_(1B_and_3B)-Conversational.py:96
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Llama3.3_(70B)_A100-Conversational.py:96
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Llama3_(8B)-Alpaca.py:89
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Llama3_(8B)-Conversational.py:88
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Llama3_(8B)-Ollama.py:88
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Llama3_(8B)-ORPO.py:87
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Llasa_TTS_(1B).py:91
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Llasa_TTS_(3B).py:91
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Magistral_(24B)-Reasoning-Conversational.py:89
- '    loftq_config = None,  # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Meta-Synthetic-Data-Llama3.1_(8B).py:335
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Meta_Synthetic_Data_Llama3_2_(3B).py:229
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Ministral_3_VL_(3B)_Vision.py:87
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Mistral_(7B)-Text_Completion.py:109
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Mistral_Nemo_(12B)-Alpaca.py:91
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Mistral_Small_(22B)-Alpaca.py:91
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Mistral_v0.3_(7B)-Alpaca.py:87
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Mistral_v0.3_(7B)-Conversational.py:87
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Mistral_v0.3_(7B)-CPT.py:98
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Nemotron-3-Nano-30B-A3B_A100.py:93
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Nemotron-Nano-3-30B-A3B_A100.py:93
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Orpheus_(3B)-TTS.py:92
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Oute_TTS_(1B).py:93
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Phi_3.5_Mini-Conversational.py:91
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Phi_3_Medium-Conversational.py:88
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Phi_4-Conversational.py:87
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Pixtral_(12B)-Vision.py:92
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Qwen2.5_(7B)-Alpaca.py:95
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Qwen2.5_Coder_(14B)-Conversational.py:98
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Qwen2.5_VL_(7B)-Vision.py:91
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Qwen2_(7B)-Alpaca.py:90
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Qwen2_5_7B_VL_GRPO.py:81
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Qwen2_VL_(7B)-Vision.py:91
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Qwen3_(14B)-Alpaca.py:97
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Qwen3_(14B)-Reasoning-Conversational.py:88
- '    loftq_config = None,  # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Qwen3_(14B).py:88
- '    loftq_config = None,  # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Qwen3_(32B)_A100-Reasoning-Conversational.py:88
- '    loftq_config = None,  # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Qwen3_(4B)-Instruct.py:89
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Qwen3_(4B)-Thinking.py:89
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Qwen3_(4B)_Instruct-QAT.py:90
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Qwen3_VL_(8B)-Vision-GRPO.py:84
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Qwen3_VL_(8B)-Vision.py:91
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Sesame_CSM_(1B)-TTS.py:75
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Spark_TTS_(0_5B).py:100
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-TinyLlama_(1.1B)-Alpaca.py:92
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Whisper.py:88
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Kaggle-Zephyr_(7B)-DPO.py:320
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Llama3.1_(8B)-Alpaca.py:91
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Llama3.2_(11B)-Vision.py:91
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Llama3.2_(1B)-RAFT.py:201
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Llama3.2_(1B_and_3B)-Conversational.py:96
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Llama3.3_(70B)_A100-Conversational.py:96
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Llama3_(8B)-Alpaca.py:89
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Llama3_(8B)-Conversational.py:88
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Llama3_(8B)-Ollama.py:88
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Llama3_(8B)-ORPO.py:87
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Llasa_TTS_(1B).py:91
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Llasa_TTS_(3B).py:91
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Magistral_(24B)-Reasoning-Conversational.py:89
- '    loftq_config = None,  # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Meta-Synthetic-Data-Llama3.1_(8B).py:359
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Meta_Synthetic_Data_Llama3_2_(3B).py:253
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Ministral_3_VL_(3B)_Vision.py:87
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Mistral_(7B)-Text_Completion.py:109
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Mistral_Nemo_(12B)-Alpaca.py:91
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Mistral_Small_(22B)-Alpaca.py:91
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Mistral_v0.3_(7B)-Alpaca.py:87
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Mistral_v0.3_(7B)-Conversational.py:87
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Mistral_v0.3_(7B)-CPT.py:98
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Nemotron-3-Nano-30B-A3B_A100.py:93
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Nemotron-Nano-3-30B-A3B_A100.py:93
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Orpheus_(3B)-TTS.py:92
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Oute_TTS_(1B).py:93
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Phi_3.5_Mini-Conversational.py:91
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Phi_3_Medium-Conversational.py:88
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Phi_4-Conversational.py:87
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Pixtral_(12B)-Vision.py:92
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Qwen2.5_(7B)-Alpaca.py:95
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Qwen2.5_Coder_(14B)-Conversational.py:98
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Qwen2.5_VL_(7B)-Vision.py:91
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Qwen2_(7B)-Alpaca.py:90
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Qwen2_5_7B_VL_GRPO.py:103
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Qwen2_VL_(7B)-Vision.py:91
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Qwen3_(14B)-Alpaca.py:97
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Qwen3_(14B)-Reasoning-Conversational.py:88
- '    loftq_config = None,  # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Qwen3_(14B).py:88
- '    loftq_config = None,  # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Qwen3_(32B)_A100-Reasoning-Conversational.py:88
- '    loftq_config = None,  # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Qwen3_(4B)-Instruct.py:89
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Qwen3_(4B)-Thinking.py:89
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Qwen3_(4B)_Instruct-QAT.py:90
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Qwen3_VL_(8B)-Vision-GRPO.py:84
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Qwen3_VL_(8B)-Vision.py:91
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Sesame_CSM_(1B)-TTS.py:75
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Spark_TTS_(0_5B).py:100
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Synthetic_Data_Hackathon.py:160
- '    loftq_config=None,'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: <none>
  comment_after: # We support LoftQ

python_scripts\TinyLlama_(1.1B)-Alpaca.py:92
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Whisper.py:88
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ

python_scripts\Zephyr_(7B)-DPO.py:320
- '    loftq_config = None, # And LoftQ'
+ '    loftq_config = None,  # We support LoftQ'
  comment_before: And LoftQ
  comment_after: # We support LoftQ
