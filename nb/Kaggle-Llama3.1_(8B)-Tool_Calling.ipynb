{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gpaavfkxjn4I"
   },
   "source": [
    "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
    "<div class=\"align-center\">\n",
    "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
    "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
    "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + \u2b50 <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> \u2b50\n",
    "</div>\n",
    "\n",
    "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://docs.unsloth.ai/get-started/installing-+-updating).\n",
    "\n",
    "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVvdJhktjn4N"
   },
   "source": [
    "### News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XH64024jn4O"
   },
   "source": [
    "**Read our [blog post](https://unsloth.ai/blog/r1-reasoning) for guidance on how to train reasoning models.**\n",
    "\n",
    "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wcPI_Fhrjn4O"
   },
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZmVkatYxjn4P"
   },
   "outputs": [],
   "source": "%%capture\n# Normally using pip install unsloth is enough\n\n# Temporarily as of Jan 31st 2025, Colab has some issues with Pytorch\n# Using pip install unsloth will take 3 minutes, whilst the below takes <1 minute:\n!pip install --no-deps bitsandbytes accelerate xformers==0.0.29 peft trl triton\n!pip install --no-deps cut_cross_entropy unsloth_zoo\n!pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n!pip install --no-deps unsloth"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQZ7n7kGjn4Q"
   },
   "source": [
    "### Unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QmUBVEnvCDJv",
    "outputId": "ecdb1165-d4e1-4026-e535-030f14fe3917"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83e\udda5 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "\ud83e\udda5 Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.2.15: Fast Llama patching. Transformers: 4.48.3.\n",
      "   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
    "fourbit_models = [\n",
    "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!\n",
    "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
    "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
    "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # We also uploaded 4bit for 405b!\n",
    "    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\", # New Mistral 12b 2x faster!\n",
    "    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n",
    "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",        # Mistral v3 2x faster!\n",
    "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
    "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
    "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
    "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
    "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n",
    "] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXd9bTZd1aaL"
   },
   "source": [
    "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6bZsfBuZDeCL",
    "outputId": "113c510e-c08e-46f0-cfbc-1a2e0e16d470",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Unsloth 2025.2.15 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vITh0KVJ10qX"
   },
   "source": [
    "<a name=\"Data\"></a>\n",
    "### Data Prep\n",
    "We now use the Glaive Function Calling dataset from [madroid](https://huggingface.co/datasets/madroid/glaive-function-calling-openai), which is a version of the original [Glaive Function Calling v2](https://huggingface.co/datasets/glaiveai/glaive-function-calling-v2) pre-processed to facilitate integration. You can replace this code section with your own data prep.\n",
    "\n",
    "**[NOTE]** Each model has its own Tool Calling template. For `llama-3.1` we'll use the [user defined custom tools](https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_1/#user-defined-custom-tool-calling) template. If you want to use another model and/or template, you'll need to write your own data prep.\n",
    "\n",
    "**[NOTE]** To train only on completions (ignoring the user's input) read TRL's docs [here](https://huggingface.co/docs/trl/sft_trainer#train-on-completions-only).\n",
    "\n",
    "**[NOTE]** Remember to add the **EOS_TOKEN** to the tokenized output!! Otherwise you'll get infinite generations!\n",
    "\n",
    "If you want to use the `llama-3` template for ShareGPT datasets, try our conversational [notebook](https://colab.research.google.com/drive/1XamvWYinY6FOSX9GLvnqSjjsNflxdhNc?usp=sharing).\n",
    "\n",
    "For text completions like novel writing, try this [notebook](https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#@title Define system prompt and message delimiters\n",
    "system_prompt = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "\n",
    "Environment: ipython\n",
    "Cutting Knowledge Date: December 2023\n",
    "Today Date: 23 July 2024\n",
    "\n",
    "# Tool Instructions\n",
    "- Always execute python code in messages that you share.\n",
    "- When looking for real time information use relevant functions if available else let the user know\n",
    "\n",
    "\n",
    "\n",
    "You have access to the following functions:\n",
    "\n",
    "{functions}\n",
    "\n",
    "\n",
    "If a you choose to call a function ONLY reply in the following format:\n",
    "<{{start_tag}}={{function_name}}>{{parameters}}{{end_tag}}\n",
    "where\n",
    "\n",
    "start_tag => `<function`\n",
    "parameters => a JSON dict with the function argument name as key and function argument value as value.\n",
    "end_tag => `</function>`\n",
    "\n",
    "Here is an example,\n",
    "<function=example_function_name>{{\"example_name\": \"example_value\"}}</function>\n",
    "\n",
    "Reminder:\n",
    "- Function calls MUST follow the specified format\n",
    "- Required parameters MUST be specified\n",
    "- Only call one function at a time\n",
    "- Put the entire function call reply on one line\n",
    "- Always add your sources when using search results to answer the user query\n",
    "\n",
    "You are a helpful assistant.<|eot_id|>\"\"\"\n",
    "\n",
    "user_message = \"<|start_header_id|>user<|end_header_id|>\\n\\n{}<|eot_id|>\"\n",
    "assistant_message = \"<|start_header_id|>assistant<|end_header_id|>                      \\n\\n{}<|eot_id|>\"\n",
    "assistant_tool_message = \"<|start_header_id|>assistant<|end_header_id|>                      \\n\\n{}<|eom_id|>\"\n",
    "tool_response_message = \"<|start_header_id|>ipython<|end_header_id|>\\n\\n{}<|eot_id|>\"\n",
    "assistant_continuation_prefix = \"<|start_header_id|>assistant<|end_header_id|>                      \"\n",
    "assistant_continuation_message = \"<|start_header_id|>assistant<|end_header_id|>                      \\n\\n{}<|eot_id|>\"\n",
    "function_string_template = \"\"\"Use the function '{name}' to: {description}\\n{schema}\"\"\""
   ],
   "metadata": {
    "id": "Vw8Ib-_zU9Eq",
    "cellView": "form"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#@title Util processing functions\n",
    "import ast, json\n",
    "\n",
    "def convert_tool_format(tool):\n",
    "    func = tool.get(\"function\", {})\n",
    "    name = func.get(\"name\", \"\")\n",
    "    description = func.get(\"description\", \"\")\n",
    "    parameters_a = func.get(\"parameters\", {})\n",
    "    properties = parameters_a.get(\"properties\", {})\n",
    "    required_params = parameters_a.get(\"required\", [])\n",
    "    def map_type(a_type, a_format=None):\n",
    "        if a_type == \"string\":\n",
    "            return \"string\"\n",
    "        elif a_type == \"number\":\n",
    "            return \"int\"\n",
    "        elif a_type == \"boolean\":\n",
    "            return \"bool\"\n",
    "        return a_type\n",
    "    parameters_b = {}\n",
    "    for param, details in properties.items():\n",
    "        parameters_b[param] = {\n",
    "            \"param_type\": map_type(details.get(\"type\"), details.get(\"format\")),\n",
    "            \"description\": details.get(\"description\", \"\"),\n",
    "            \"required\": param in required_params\n",
    "        }\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"description\": description,\n",
    "        \"parameters\": parameters_b\n",
    "    }\n",
    "\n",
    "def get_function_string(f):\n",
    "    converted_tool = convert_tool_format(f)\n",
    "    return function_string_template.format(\n",
    "        name=converted_tool[\"name\"],\n",
    "        description=converted_tool[\"description\"],\n",
    "        schema=json.dumps(converted_tool)\n",
    "    )\n",
    "\n",
    "def convert_function_call_format(call):\n",
    "    func_data = call.get(\"function\", {})\n",
    "    func_name = func_data.get(\"name\", \"\")\n",
    "    arguments_str = func_data.get(\"arguments\", \"{}\")\n",
    "    try:\n",
    "        arguments_dict = ast.literal_eval(arguments_str)\n",
    "    except Exception:\n",
    "        arguments_dict = {}\n",
    "    arguments_json = json.dumps(arguments_dict)\n",
    "    return f\"<function={func_name}>{arguments_json}</function>\"\n",
    "\n",
    "def process_block(block):\n",
    "    tool_index = None\n",
    "    for i, msg in enumerate(block):\n",
    "        if msg[\"role\"] == \"assistant\" and \"tool_calls\" in msg:\n",
    "            tool_index = i\n",
    "            break\n",
    "    filtered_block = []\n",
    "    if tool_index is not None:\n",
    "        for i, msg in enumerate(block):\n",
    "            if msg[\"role\"] == \"assistant\" and i < tool_index:\n",
    "                continue\n",
    "            filtered_block.append(msg)\n",
    "    else:\n",
    "        filtered_block = block\n",
    "    block_context = \"\"\n",
    "    tool_called = False\n",
    "    for msg in filtered_block:\n",
    "        if msg[\"role\"] == \"assistant\":\n",
    "            if \"tool_calls\" in msg:\n",
    "                block_context += assistant_tool_message.format(convert_function_call_format(msg[\"tool_calls\"][0]))\n",
    "            else:\n",
    "                if tool_called:\n",
    "                    block_context += assistant_continuation_message.format(msg[\"content\"])\n",
    "                    tool_called = False\n",
    "                else:\n",
    "                    block_context += assistant_message.format(msg[\"content\"])\n",
    "        elif msg[\"role\"] == \"tool\":\n",
    "            block_context += tool_response_message.format(msg[\"content\"])\n",
    "            tool_called = True\n",
    "    return block_context\n",
    "\n",
    "def get_formatted_sample(sample):\n",
    "    functions_string = \"\\n\\n\".join([get_function_string(f) for f in sample.get(\"tools\", [])])\n",
    "    context = system_prompt.format(functions=functions_string)\n",
    "    block = []\n",
    "    for message in sample[\"messages\"]:\n",
    "        if message[\"role\"] == \"system\":\n",
    "            continue\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            if block:\n",
    "                context += process_block(block)\n",
    "                block = []\n",
    "            context += user_message.format(message[\"content\"])\n",
    "        else:\n",
    "            block.append(message)\n",
    "    if block:\n",
    "        context += process_block(block)\n",
    "    return context\n"
   ],
   "metadata": {
    "id": "8vdlWCEoVAN2"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LjY75GoYUCB8",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "a260c69c1bc24faaba45c4d96f6ea2f6",
      "3ed1d73212784ebf81c2496cff7e1f2a",
      "53565e6b78004ef9b447121f84985bb7",
      "86edadf55c99416e911ad55d52494038",
      "819ba37f02e549b3bd4b3b7b87f56d1f",
      "ea72b5a4fcc54096870d16e6ecb0ca3a",
      "7f7aeb38c44a4732af38180fcfb1da6c",
      "c607cb289d05404386be3c5c87d83836",
      "a5f08b69b7e4432e9d983ac974e09b38",
      "9b727b7e5455450d94724eec947e3004",
      "848e8392e481410badcdccd57d13dee7"
     ]
    },
    "outputId": "0555f238-be41-4bbf-b0d6-3e94ea231cc9"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/112754 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a260c69c1bc24faaba45c4d96f6ea2f6"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "#@title Process dataset\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    _json = examples[\"json\"]\n",
    "    texts = []\n",
    "    for sample_obj in _json:\n",
    "        # sample_obj = json.loads(sample[\"json\"])\n",
    "        text = get_formatted_sample(json.loads(sample_obj))\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "pass\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"madroid/glaive-function-calling-openai\", split = \"train\")\n",
    "dataset = dataset.map(formatting_prompts_func, batched = True,)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(dataset[0][\"text\"])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dfao4tIBzOhi",
    "outputId": "215759e5-f5ce-4e37-d478-bb2f2f952eec"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "\n",
      "Environment: ipython\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 23 July 2024\n",
      "\n",
      "# Tool Instructions\n",
      "- Always execute python code in messages that you share.\n",
      "- When looking for real time information use relevant functions if available else let the user know\n",
      "\n",
      "\n",
      "\n",
      "You have access to the following functions:\n",
      "\n",
      "Use the function 'track_calories' to: Track daily calorie intake\n",
      "{\"name\": \"track_calories\", \"description\": \"Track daily calorie intake\", \"parameters\": {\"meal\": {\"param_type\": \"string\", \"description\": \"The meal for which calories are being tracked\", \"required\": true}, \"calories\": {\"param_type\": \"int\", \"description\": \"The number of calories consumed\", \"required\": true}, \"date\": {\"param_type\": \"string\", \"description\": \"The date for which calories are being tracked\", \"required\": true}}}\n",
      "\n",
      "\n",
      "If a you choose to call a function ONLY reply in the following format:\n",
      "<{start_tag}={function_name}>{parameters}{end_tag}\n",
      "where\n",
      "\n",
      "start_tag => `<function`\n",
      "parameters => a JSON dict with the function argument name as key and function argument value as value.\n",
      "end_tag => `</function>`\n",
      "\n",
      "Here is an example,\n",
      "<function=example_function_name>{\"example_name\": \"example_value\"}</function>\n",
      "\n",
      "Reminder:\n",
      "- Function calls MUST follow the specified format\n",
      "- Required parameters MUST be specified\n",
      "- Only call one function at a time\n",
      "- Put the entire function call reply on one line\n",
      "- Always add your sources when using search results to answer the user query\n",
      "\n",
      "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hi, I had a pizza for lunch today which was about 800 calories. Can you track this for me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>                      \n",
      "\n",
      "<function=track_calories>{\"meal\": \"pizza\", \"calories\": 800, \"date\": \"2022-03-01\"}</function><|eom_id|><|start_header_id|>ipython<|end_header_id|>\n",
      "\n",
      "{\"status\": \"success\", \"message\": \"Calories for your pizza meal have been successfully tracked for the date 2022-03-01\"}<|eot_id|><|start_header_id|>assistant<|end_header_id|>                      \n",
      "\n",
      "Great! The calories for your pizza meal have been successfully tracked for today.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "That's awesome! Can you also order a pizza for me from the nearest pizza place?<|eot_id|><|start_header_id|>assistant<|end_header_id|>                      \n",
      "\n",
      "I'm sorry, but as an AI, I don't have the capability to perform external tasks such as placing orders. My primary function is to assist you with the functions provided to me, such as tracking your calorie intake.<|eot_id|>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idAEIeSQ3xdS"
   },
   "source": [
    "<a name=\"Train\"></a>\n",
    "### Train the model\n",
    "Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "3237e04b476b4142ae8a0309dcdf327a",
      "8b94291cab6240c596621923a4bfc213",
      "6c3fb60f196a46799685f7cbbb0be28e",
      "c259833aa6d148749293cb0bd7849089",
      "a32b643a370d4c8faac31cb30aba28dd",
      "25cba0c7c3b64666879ea3157d4b43fb",
      "e5cf8fa8df7e458881e2fc468cc707e4",
      "fe67b32b5edd4808916aa9e63a8c8d9b",
      "7b5ba5b5da384cbcb422f945740a755d",
      "808f9973de6844b584dd53b630a398e5",
      "e1a68f9deb114c0e8da8229edf323926",
      "b5b51a206563427eac85fe849439b99f",
      "ba61fdc809444053969d58813a608d6d",
      "cc40514e343f4f559049b616b2eacc1f",
      "7db6511d4abe4e358ad04ae5ec166140",
      "e0785da126f547748282d18c4b79fd58",
      "19343326b2de49079565b8e64b67e031",
      "458d4fb43fd34a54bf4c6afb8dff2849",
      "74a06f38b6f54ce6a21ce43edc9f1641",
      "2e5ea29454bb462a9d2eaef3aaf4b186",
      "be011cc34c674ef9a237858b6ff8f728",
      "f3f34dd0896847fc9161d1a158f60f13",
      "3b063da052a44e7abfb00a1f52945e2a",
      "1e73832bd5ad4d808a719e446c78dec0",
      "5e25580d97b34fafa75f9b1dc3d1882f",
      "6e7c8c1e2c434f468eb2f412031d4f7c",
      "b9b6dc43ef474d3a972f2e4ee6852dca",
      "89d0ea94a2314c7a8a88943cf641a649",
      "04e79c7f06294ab8a8074e2e2916fa56",
      "2f17a530623049b59b1a5197e7f80370",
      "40915aa8e4e84dd7a58c0738e707fe1b",
      "3efc83359f7b4d99b70d6ab9fa25d23a",
      "91fa89bb400741b4a0fe046b1365dc42",
      "6cd1b567f37e479eb3d1cdab522dd39d",
      "4997c8e41a3e423a9b3ebe0081746931",
      "01825c2a354d40799555a990ba73996b",
      "8f2fd22e31f4485ba97f2fe38e61c9f0",
      "1921af3669174ac087763cdc506ee76d",
      "269f717369c64b90b7e80fbb9c1a9997",
      "4fb7436f92ee48cdac83c344904dcccf",
      "eb7a01cb8f3848eb94734efa0aee1e61",
      "4dc4406ad32e4abf8a491fb59006b491",
      "87334ad1ff3f4281977968469e37183d",
      "ea5cc23294cc474e93840332d604971a"
     ]
    },
    "id": "95_Nn-89DhsL",
    "outputId": "3bfafb60-d7f4-45b5-9937-4b3d1d84bc14"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Converting train dataset to ChatML (num_proc=2):   0%|          | 0/112754 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3237e04b476b4142ae8a0309dcdf327a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Applying chat template to train dataset (num_proc=2):   0%|          | 0/112754 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b5b51a206563427eac85fe849439b99f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Tokenizing train dataset (num_proc=2):   0%|          | 0/112754 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b063da052a44e7abfb00a1f52945e2a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Truncating train dataset (num_proc=2):   0%|          | 0/112754 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6cd1b567f37e479eb3d1cdab522dd39d"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        max_steps = 60,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": "form",
    "id": "2ejIt2xSNKKp",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "85db6ec0-4f15-4565-b9e3-ff39611c31ac"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GPU = Tesla T4. Max memory = 14.741 GB.\n",
      "5.516 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "# @title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "yqxqAZ7KJ4oL",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "922eba74-3147-4c92-f120-eebd234abea2"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 112,754 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 60\n",
      " \"-____-\"     Number of trainable parameters = 41,943,040\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 20:26, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.022000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.373700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.681200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.539600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.761500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.689500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.524600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.107300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.122800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.948900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.939600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.820500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.788200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.609800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.652800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.639200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.374600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.437900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.420400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.449600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.460100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.490300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.400400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.287900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.439200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.502500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.201300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.442800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.377000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.598200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.460600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.201500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.437300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.341100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.322100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.595400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.289700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.415600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.298400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.492500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.508200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.188600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.425400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.261800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.506300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.411200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.165600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.544000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.265200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.476600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.308800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.237200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.361200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.309200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.375700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.369600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.333500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.573200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.230900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellView": "form",
    "id": "pCqnaKmlO1U9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "67e4f04c-5ade-4097-b775-5d6b27a6289a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1263.8918 seconds used for training.\n",
      "21.06 minutes used for training.\n",
      "Peak reserved memory = 7.467 GB.\n",
      "Peak reserved memory for training = 1.951 GB.\n",
      "Peak reserved memory % of max memory = 50.655 %.\n",
      "Peak reserved memory for training % of max memory = 13.235 %.\n"
     ]
    }
   ],
   "source": [
    "# @title Show final memory and time stats\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory / max_memory * 100, 3)\n",
    "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(\n",
    "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
    ")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekOmTR1hSNcr"
   },
   "source": [
    "<a name=\"Inference\"></a>\n",
    "### Inference\n",
    "Let's run the model! We'll load the `test` split of our dataset and prepare it to generation.\n",
    "\n",
    "**[NOTE]** To use the model's tool calling capabilities in a more streamlined way you should use a scaffolding framework such as [llama-stack-apps](https://github.com/meta-llama/llama-stack-apps). For the scope of this demo we will test the model manually.\n",
    "\n",
    "**[NEW] Try 2x faster inference in a free Colab for Llama-3.1 8b Instruct [here](https://colab.research.google.com/drive/1T-YBVfnphoVc8E2E854qF3jdia2Ll2W2?usp=sharing)**"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dataset_test = load_dataset(\"madroid/glaive-function-calling-openai\", split = \"test\")\n",
    "dataset_test = dataset_test.map(formatting_prompts_func, batched = True,)"
   ],
   "metadata": {
    "id": "5iUqU8oqg1Ij",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "3623ca82f6ef49c285ffde06c2265d47",
      "f12f63657f344aaaae37d0b926ef2a67",
      "174598c6bb8946bfb288980ecfb41043",
      "e57a6673a2b24f61a86952868d19398b",
      "03aa9cc5cce4488dbf4d82d62e72af16",
      "5c29f4e94b2647f3abadfacaa590e2bb",
      "70701b3922a84f0eaaa8eaffeb9787d3",
      "2c2099110ef84a89a8eac9b4ac02106a",
      "5c38cfd5e75f4ab98d1613f95fcf8733",
      "52a792e911f649b9b051ce1578832686",
      "2b09ff9587ab4ff5a07a8e46bb49b413"
     ]
    },
    "outputId": "0a0ab140-af55-4dbc-e2c1-b85e44e2eae9"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/967 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3623ca82f6ef49c285ffde06c2265d47"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Model determining which tool to call**\n",
    "\n",
    "We feed the model with the generation prompt. It responds with a tool call in the following format:\n",
    "\n",
    "```\n",
    "\n",
    "<function=example_function_name>{\"example_name\": \"example_value\"}</function><|eom_id|>\n",
    "```"
   ],
   "metadata": {
    "id": "ke46c6SptW9m"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kR3gIAX-SM2q",
    "outputId": "d87f4648-2361-472f-9bab-3618bc8ed6ca"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "\n",
      "Environment: ipython\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 23 July 2024\n",
      "\n",
      "# Tool Instructions\n",
      "- Always execute python code in messages that you share.\n",
      "- When looking for real time information use relevant functions if available else let the user know\n",
      "\n",
      "\n",
      "\n",
      "You have access to the following functions:\n",
      "\n",
      "Use the function 'calculate_fuel_consumption' to: Calculate the fuel consumption based on distance and fuel efficiency\n",
      "{\"name\": \"calculate_fuel_consumption\", \"description\": \"Calculate the fuel consumption based on distance and fuel efficiency\", \"parameters\": {\"distance\": {\"param_type\": \"int\", \"description\": \"The distance traveled\", \"required\": true}, \"fuel_efficiency\": {\"param_type\": \"int\", \"description\": \"The fuel efficiency in kilometers per liter\", \"required\": true}}}\n",
      "\n",
      "\n",
      "If a you choose to call a function ONLY reply in the following format:\n",
      "<{start_tag}={function_name}>{parameters}{end_tag}\n",
      "where\n",
      "\n",
      "start_tag => `<function`\n",
      "parameters => a JSON dict with the function argument name as key and function argument value as value.\n",
      "end_tag => `</function>`\n",
      "\n",
      "Here is an example,\n",
      "<function=example_function_name>{\"example_name\": \"example_value\"}</function>\n",
      "\n",
      "Reminder:\n",
      "- Function calls MUST follow the specified format\n",
      "- Required parameters MUST be specified\n",
      "- Only call one function at a time\n",
      "- Put the entire function call reply on one line\n",
      "- Always add your sources when using search results to answer the user query\n",
      "\n",
      "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hi, I need to calculate the fuel consumption for my car. I have traveled 500 kilometers and my car's fuel efficiency is 20 kilometers per liter. Can you help me with that?<|eot_id|><|start_header_id|>assistant<|end_header_id|>                      \n",
      "==============================\n",
      "                 \n",
      "\n",
      "<function=calculate_fuel_consumption>{\"distance\": 500, \"fuel_efficiency\": 20}</function><|eom_id|>\n"
     ]
    }
   ],
   "source": [
    "test_sample = dataset_test[128][\"text\"]\n",
    "\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "\n",
    "\n",
    "context = test_sample+assistant_continuation_prefix\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    context,\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "print(context)\n",
    "print(\"===\"*10)\n",
    "\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n",
    "output_text = tokenizer.batch_decode(outputs)[0]\n",
    "\n",
    "\n",
    "output_text = output_text[len(context):]\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#@title **User-defined Custom tools**\n",
    "import re\n",
    "import json\n",
    "\n",
    "\n",
    "# function to parse model's response\n",
    "def parse_function_call(s: str):\n",
    "    # Regex pattern to extract function name and JSON arguments\n",
    "    match = re.search(r\"<function=(\\w+)>(\\{.*?\\})</function>\", s)\n",
    "\n",
    "    if match:\n",
    "        function_name = match.group(1)  # Extract function name\n",
    "        args_json = match.group(2)      # Extract JSON string\n",
    "        args = json.loads(args_json)    # Parse JSON to dictionary\n",
    "        return function_name, args\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "# CUSTOM TOOLS\n",
    "def calculate_loan_emi(loan_amount: int, interest_rate: int, loan_term: int) -> float:\n",
    "    monthly_interest_rate = (interest_rate / 100) / 12\n",
    "\n",
    "    if monthly_interest_rate == 0:\n",
    "        emi = loan_amount / loan_term\n",
    "    else:\n",
    "        emi = (loan_amount * monthly_interest_rate * (1 + monthly_interest_rate) ** loan_term) / \\\n",
    "              ((1 + monthly_interest_rate) ** loan_term - 1)\n",
    "\n",
    "    return round(emi, 2)\n",
    "\n",
    "\n",
    "def calculate_fuel_consumption(distance: int, fuel_efficiency: int) -> float:\n",
    "    if fuel_efficiency <= 0:\n",
    "        raise ValueError(\"Fuel efficiency must be greater than zero.\")\n",
    "\n",
    "    fuel_consumed = distance / fuel_efficiency\n",
    "    return round(fuel_consumed, 2)\n",
    "\n",
    "\n",
    "TOOLS = {\n",
    "    \"calculate_loan_emi\": calculate_loan_emi,\n",
    "    \"calculate_fuel_consumption\": calculate_fuel_consumption,\n",
    "}"
   ],
   "metadata": {
    "id": "ln4cwSVJqLjh"
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Result from calling the tool is passed back to the model and it generates the final response the user**\n",
    "\n",
    "Now we add the tool call from the previous generation and its result to the context, the model then generates the final response."
   ],
   "metadata": {
    "id": "sFiDaiRPuOzw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Parse and execute tool given model output\n",
    "function_name, arguments = parse_function_call(output_text)\n",
    "\n",
    "\n",
    "if function_name is not None:\n",
    "  tool_response = TOOLS[function_name](**arguments)\n",
    "\n",
    "  # Prepare context\n",
    "  context = test_sample # original input\n",
    "  # Add tool call and response\n",
    "  context += assistant_tool_message.format(output_text)\n",
    "  context += tool_response_message.format(tool_response)\n",
    "  # Add generation prompt\n",
    "  context += assistant_continuation_prefix\n",
    "\n",
    "  FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "  inputs = tokenizer(\n",
    "  [\n",
    "      context\n",
    "  ], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "  print(context)\n",
    "  print(\"===\"*20)\n",
    "\n",
    "  outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n",
    "\n",
    "  output_text_chat = tokenizer.batch_decode(outputs)\n",
    "  output_text_chat = output_text_chat[0][len(context):]\n",
    "  print(output_text_chat)"
   ],
   "metadata": {
    "id": "Ww_lGt0_uj82",
    "outputId": "0b8d80ea-d017-493f-9509-e62804d8e71d",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "\n",
      "Environment: ipython\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 23 July 2024\n",
      "\n",
      "# Tool Instructions\n",
      "- Always execute python code in messages that you share.\n",
      "- When looking for real time information use relevant functions if available else let the user know\n",
      "\n",
      "\n",
      "\n",
      "You have access to the following functions:\n",
      "\n",
      "Use the function 'calculate_fuel_consumption' to: Calculate the fuel consumption based on distance and fuel efficiency\n",
      "{\"name\": \"calculate_fuel_consumption\", \"description\": \"Calculate the fuel consumption based on distance and fuel efficiency\", \"parameters\": {\"distance\": {\"param_type\": \"int\", \"description\": \"The distance traveled\", \"required\": true}, \"fuel_efficiency\": {\"param_type\": \"int\", \"description\": \"The fuel efficiency in kilometers per liter\", \"required\": true}}}\n",
      "\n",
      "\n",
      "If a you choose to call a function ONLY reply in the following format:\n",
      "<{start_tag}={function_name}>{parameters}{end_tag}\n",
      "where\n",
      "\n",
      "start_tag => `<function`\n",
      "parameters => a JSON dict with the function argument name as key and function argument value as value.\n",
      "end_tag => `</function>`\n",
      "\n",
      "Here is an example,\n",
      "<function=example_function_name>{\"example_name\": \"example_value\"}</function>\n",
      "\n",
      "Reminder:\n",
      "- Function calls MUST follow the specified format\n",
      "- Required parameters MUST be specified\n",
      "- Only call one function at a time\n",
      "- Put the entire function call reply on one line\n",
      "- Always add your sources when using search results to answer the user query\n",
      "\n",
      "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hi, I need to calculate the fuel consumption for my car. I have traveled 500 kilometers and my car's fuel efficiency is 20 kilometers per liter. Can you help me with that?<|eot_id|><|start_header_id|>assistant<|end_header_id|>                      \n",
      "\n",
      "                 \n",
      "\n",
      "<function=calculate_fuel_consumption>{\"distance\": 500, \"fuel_efficiency\": 20}</function><|eom_id|><|eom_id|><|start_header_id|>ipython<|end_header_id|>\n",
      "\n",
      "25.0<|eot_id|><|start_header_id|>assistant<|end_header_id|>                      \n",
      "============================================================\n",
      "                 \n",
      "\n",
      "The fuel consumption for your car would be 25.0 liters.<|eot_id|>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CrSvZObor0lY"
   },
   "source": [
    " You can also use a `TextStreamer` for continuous inference - so you can see the generation token by token, instead of waiting the whole time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2pEuRb1r2Vg",
    "outputId": "6a7c4e8a-3015-4026-d5f2-bf131c5b4953"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "\n",
      "Environment: ipython\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 23 July 2024\n",
      "\n",
      "# Tool Instructions\n",
      "- Always execute python code in messages that you share.\n",
      "- When looking for real time information use relevant functions if available else let the user know\n",
      "\n",
      "\n",
      "\n",
      "You have access to the following functions:\n",
      "\n",
      "Use the function 'calculate_fuel_consumption' to: Calculate the fuel consumption based on distance and fuel efficiency\n",
      "{\"name\": \"calculate_fuel_consumption\", \"description\": \"Calculate the fuel consumption based on distance and fuel efficiency\", \"parameters\": {\"distance\": {\"param_type\": \"int\", \"description\": \"The distance traveled\", \"required\": true}, \"fuel_efficiency\": {\"param_type\": \"int\", \"description\": \"The fuel efficiency in kilometers per liter\", \"required\": true}}}\n",
      "\n",
      "\n",
      "If a you choose to call a function ONLY reply in the following format:\n",
      "<{start_tag}={function_name}>{parameters}{end_tag}\n",
      "where\n",
      "\n",
      "start_tag => `<function`\n",
      "parameters => a JSON dict with the function argument name as key and function argument value as value.\n",
      "end_tag => `</function>`\n",
      "\n",
      "Here is an example,\n",
      "<function=example_function_name>{\"example_name\": \"example_value\"}</function>\n",
      "\n",
      "Reminder:\n",
      "- Function calls MUST follow the specified format\n",
      "- Required parameters MUST be specified\n",
      "- Only call one function at a time\n",
      "- Put the entire function call reply on one line\n",
      "- Always add your sources when using search results to answer the user query\n",
      "\n",
      "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hi, I need to calculate the fuel consumption for my car. I have traveled 500 kilometers and my car's fuel efficiency is 20 kilometers per liter. Can you help me with that?<|eot_id|><|start_header_id|>assistant<|end_header_id|>                      \n",
      "\n",
      "<function=calculate_fuel_consumption>{\"distance\": 500, \"fuel_efficiency\": 20}</function><|eom_id|>\n"
     ]
    }
   ],
   "source": [
    "# alpaca_prompt = Copied from above\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    test_sample+assistant_continuation_prefix,\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMuVrWbjAzhc"
   },
   "source": [
    "<a name=\"Save\"></a>\n",
    "### Saving, loading finetuned models\n",
    "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
    "\n",
    "**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "upcOlWe7A1vc",
    "outputId": "973e4561-f354-4595-eaf9-1a0f7f18fc4f"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('lora_model/tokenizer_config.json',\n",
       " 'lora_model/special_tokens_map.json',\n",
       " 'lora_model/tokenizer.json')"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "model.save_pretrained(\"lora_model\")  # Local saving\n",
    "tokenizer.save_pretrained(\"lora_model\")\n",
    "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n",
    "# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEEcJ4qfC7Lp"
   },
   "source": [
    "Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MKX_XKs_BNZR",
    "outputId": "4297ecc7-fac6-4c8e-8e50-6f5887fc9ed0"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "\n",
      "Environment: ipython\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 23 July 2024\n",
      "\n",
      "# Tool Instructions\n",
      "- Always execute python code in messages that you share.\n",
      "- When looking for real time information use relevant functions if available else let the user know\n",
      "\n",
      "\n",
      "\n",
      "You have access to the following functions:\n",
      "\n",
      "Use the function 'calculate_fuel_consumption' to: Calculate the fuel consumption based on distance and fuel efficiency\n",
      "{\"name\": \"calculate_fuel_consumption\", \"description\": \"Calculate the fuel consumption based on distance and fuel efficiency\", \"parameters\": {\"distance\": {\"param_type\": \"int\", \"description\": \"The distance traveled\", \"required\": true}, \"fuel_efficiency\": {\"param_type\": \"int\", \"description\": \"The fuel efficiency in kilometers per liter\", \"required\": true}}}\n",
      "\n",
      "\n",
      "If a you choose to call a function ONLY reply in the following format:\n",
      "<{start_tag}={function_name}>{parameters}{end_tag}\n",
      "where\n",
      "\n",
      "start_tag => `<function`\n",
      "parameters => a JSON dict with the function argument name as key and function argument value as value.\n",
      "end_tag => `</function>`\n",
      "\n",
      "Here is an example,\n",
      "<function=example_function_name>{\"example_name\": \"example_value\"}</function>\n",
      "\n",
      "Reminder:\n",
      "- Function calls MUST follow the specified format\n",
      "- Required parameters MUST be specified\n",
      "- Only call one function at a time\n",
      "- Put the entire function call reply on one line\n",
      "- Always add your sources when using search results to answer the user query\n",
      "\n",
      "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hi, I need to calculate the fuel consumption for my car. I have traveled 500 kilometers and my car's fuel efficiency is 20 kilometers per liter. Can you help me with that?<|eot_id|><|start_header_id|>assistant<|end_header_id|>                      \n",
      "==============================\n",
      "                 \n",
      "\n",
      "<function=calculate_fuel_consumption>{\"distance\": 500, \"fuel_efficiency\": 20}</function><|eom_id|>\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    from unsloth import FastLanguageModel\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "        max_seq_length = max_seq_length,\n",
    "        dtype = dtype,\n",
    "        load_in_4bit = load_in_4bit,\n",
    "    )\n",
    "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "\n",
    "test_sample = dataset_test[128][\"text\"]\n",
    "context = test_sample+assistant_continuation_prefix\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    context,\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "print(context)\n",
    "print(\"===\"*10)\n",
    "\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n",
    "output_text = tokenizer.batch_decode(outputs)[0]\n",
    "\n",
    "\n",
    "output_text = output_text[len(context):]\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQMjaNrjsU5_"
   },
   "source": [
    "You can also use Hugging Face's `AutoModelForPeftCausalLM`. Only use this if you do not have `unsloth` installed. It can be hopelessly slow, since `4bit` model downloading is not supported, and Unsloth's **inference is 2x faster**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yFfaXG0WsQuE"
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    # I highly do NOT suggest - use Unsloth if possible\n",
    "    from peft import AutoPeftModelForCausalLM\n",
    "    from transformers import AutoTokenizer\n",
    "    model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "        \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "        load_in_4bit = load_in_4bit,\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"lora_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f422JgM9sdVT"
   },
   "source": [
    "### Saving to float16 for VLLM\n",
    "\n",
    "We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iHjt_SMYsd3P"
   },
   "outputs": [],
   "source": [
    "# Merge to 16bit\n",
    "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
    "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
    "\n",
    "# Merge to 4bit\n",
    "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
    "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
    "\n",
    "# Just LoRA adapters\n",
    "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n",
    "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCv4vXHd61i7"
   },
   "source": [
    "### GGUF / llama.cpp Conversion\n",
    "To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n",
    "\n",
    "Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n",
    "* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n",
    "* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n",
    "* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K.\n",
    "\n",
    "[**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FqfebeAdT073"
   },
   "outputs": [],
   "source": [
    "# Save to 8bit Q8_0\n",
    "if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n",
    "# Remember to go to https://huggingface.co/settings/tokens for a token!\n",
    "# And change hf to your username!\n",
    "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
    "\n",
    "# Save to 16bit GGUF\n",
    "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
    "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
    "\n",
    "# Save to q4_k_m GGUF\n",
    "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
    "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n",
    "\n",
    "# Save to multiple GGUF options - much faster if you want multiple!\n",
    "if False:\n",
    "    model.push_to_hub_gguf(\n",
    "        \"hf/model\", # Change hf to your username!\n",
    "        tokenizer,\n",
    "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
    "        token = \"\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lh6A70Xzjn4Z"
   },
   "source": [
    "Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in llama.cpp or a UI based system like Jan or Open WebUI. You can install Jan [here](https://github.com/janhq/jan) and Open WebUI [here](https://github.com/open-webui/open-webui)\n",
    "\n",
    "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/unsloth) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
    "\n",
    "Some other links:\n",
    "1. Llama 3.2 Conversational notebook. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(1B_and_3B)-Conversational.ipynb)\n",
    "2. Saving finetunes to Ollama. [Free notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)\n",
    "3. Llama 3.2 Vision finetuning - Radiography use case. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb)\n",
    "6. See notebooks for DPO, ORPO, Continued pretraining, conversational finetuning and more on our [documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks)!\n",
    "\n",
    "<div class=\"align-center\">\n",
    "  <a href=\"https://unsloth.ai\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
    "  <a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
    "  <a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a>\n",
    "\n",
    "  Join Discord if you need help + \u2b50\ufe0f <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> \u2b50\ufe0f\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "a260c69c1bc24faaba45c4d96f6ea2f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3ed1d73212784ebf81c2496cff7e1f2a",
       "IPY_MODEL_53565e6b78004ef9b447121f84985bb7",
       "IPY_MODEL_86edadf55c99416e911ad55d52494038"
      ],
      "layout": "IPY_MODEL_819ba37f02e549b3bd4b3b7b87f56d1f"
     }
    },
    "3ed1d73212784ebf81c2496cff7e1f2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea72b5a4fcc54096870d16e6ecb0ca3a",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_7f7aeb38c44a4732af38180fcfb1da6c",
      "value": "Map:\u2007100%"
     }
    },
    "53565e6b78004ef9b447121f84985bb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c607cb289d05404386be3c5c87d83836",
      "max": 112754,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a5f08b69b7e4432e9d983ac974e09b38",
      "value": 112754
     }
    },
    "86edadf55c99416e911ad55d52494038": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b727b7e5455450d94724eec947e3004",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_848e8392e481410badcdccd57d13dee7",
      "value": "\u2007112754/112754\u2007[00:23&lt;00:00,\u20073700.54\u2007examples/s]"
     }
    },
    "819ba37f02e549b3bd4b3b7b87f56d1f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea72b5a4fcc54096870d16e6ecb0ca3a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f7aeb38c44a4732af38180fcfb1da6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c607cb289d05404386be3c5c87d83836": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5f08b69b7e4432e9d983ac974e09b38": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9b727b7e5455450d94724eec947e3004": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "848e8392e481410badcdccd57d13dee7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3237e04b476b4142ae8a0309dcdf327a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8b94291cab6240c596621923a4bfc213",
       "IPY_MODEL_6c3fb60f196a46799685f7cbbb0be28e",
       "IPY_MODEL_c259833aa6d148749293cb0bd7849089"
      ],
      "layout": "IPY_MODEL_a32b643a370d4c8faac31cb30aba28dd"
     }
    },
    "8b94291cab6240c596621923a4bfc213": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_25cba0c7c3b64666879ea3157d4b43fb",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_e5cf8fa8df7e458881e2fc468cc707e4",
      "value": "Converting\u2007train\u2007dataset\u2007to\u2007ChatML\u2007(num_proc=2):\u2007100%"
     }
    },
    "6c3fb60f196a46799685f7cbbb0be28e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe67b32b5edd4808916aa9e63a8c8d9b",
      "max": 112754,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7b5ba5b5da384cbcb422f945740a755d",
      "value": 112754
     }
    },
    "c259833aa6d148749293cb0bd7849089": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_808f9973de6844b584dd53b630a398e5",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_e1a68f9deb114c0e8da8229edf323926",
      "value": "\u2007112754/112754\u2007[00:10&lt;00:00,\u200717409.56\u2007examples/s]"
     }
    },
    "a32b643a370d4c8faac31cb30aba28dd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25cba0c7c3b64666879ea3157d4b43fb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5cf8fa8df7e458881e2fc468cc707e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fe67b32b5edd4808916aa9e63a8c8d9b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b5ba5b5da384cbcb422f945740a755d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "808f9973de6844b584dd53b630a398e5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1a68f9deb114c0e8da8229edf323926": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b5b51a206563427eac85fe849439b99f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ba61fdc809444053969d58813a608d6d",
       "IPY_MODEL_cc40514e343f4f559049b616b2eacc1f",
       "IPY_MODEL_7db6511d4abe4e358ad04ae5ec166140"
      ],
      "layout": "IPY_MODEL_e0785da126f547748282d18c4b79fd58"
     }
    },
    "ba61fdc809444053969d58813a608d6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_19343326b2de49079565b8e64b67e031",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_458d4fb43fd34a54bf4c6afb8dff2849",
      "value": "Applying\u2007chat\u2007template\u2007to\u2007train\u2007dataset\u2007(num_proc=2):\u2007100%"
     }
    },
    "cc40514e343f4f559049b616b2eacc1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_74a06f38b6f54ce6a21ce43edc9f1641",
      "max": 112754,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2e5ea29454bb462a9d2eaef3aaf4b186",
      "value": 112754
     }
    },
    "7db6511d4abe4e358ad04ae5ec166140": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be011cc34c674ef9a237858b6ff8f728",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_f3f34dd0896847fc9161d1a158f60f13",
      "value": "\u2007112754/112754\u2007[00:09&lt;00:00,\u200718986.40\u2007examples/s]"
     }
    },
    "e0785da126f547748282d18c4b79fd58": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "19343326b2de49079565b8e64b67e031": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "458d4fb43fd34a54bf4c6afb8dff2849": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "74a06f38b6f54ce6a21ce43edc9f1641": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e5ea29454bb462a9d2eaef3aaf4b186": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "be011cc34c674ef9a237858b6ff8f728": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3f34dd0896847fc9161d1a158f60f13": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3b063da052a44e7abfb00a1f52945e2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1e73832bd5ad4d808a719e446c78dec0",
       "IPY_MODEL_5e25580d97b34fafa75f9b1dc3d1882f",
       "IPY_MODEL_6e7c8c1e2c434f468eb2f412031d4f7c"
      ],
      "layout": "IPY_MODEL_b9b6dc43ef474d3a972f2e4ee6852dca"
     }
    },
    "1e73832bd5ad4d808a719e446c78dec0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89d0ea94a2314c7a8a88943cf641a649",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_04e79c7f06294ab8a8074e2e2916fa56",
      "value": "Tokenizing\u2007train\u2007dataset\u2007(num_proc=2):\u2007100%"
     }
    },
    "5e25580d97b34fafa75f9b1dc3d1882f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f17a530623049b59b1a5197e7f80370",
      "max": 112754,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_40915aa8e4e84dd7a58c0738e707fe1b",
      "value": 112754
     }
    },
    "6e7c8c1e2c434f468eb2f412031d4f7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3efc83359f7b4d99b70d6ab9fa25d23a",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_91fa89bb400741b4a0fe046b1365dc42",
      "value": "\u2007112754/112754\u2007[03:52&lt;00:00,\u2007584.47\u2007examples/s]"
     }
    },
    "b9b6dc43ef474d3a972f2e4ee6852dca": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89d0ea94a2314c7a8a88943cf641a649": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04e79c7f06294ab8a8074e2e2916fa56": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f17a530623049b59b1a5197e7f80370": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40915aa8e4e84dd7a58c0738e707fe1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3efc83359f7b4d99b70d6ab9fa25d23a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91fa89bb400741b4a0fe046b1365dc42": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6cd1b567f37e479eb3d1cdab522dd39d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4997c8e41a3e423a9b3ebe0081746931",
       "IPY_MODEL_01825c2a354d40799555a990ba73996b",
       "IPY_MODEL_8f2fd22e31f4485ba97f2fe38e61c9f0"
      ],
      "layout": "IPY_MODEL_1921af3669174ac087763cdc506ee76d"
     }
    },
    "4997c8e41a3e423a9b3ebe0081746931": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_269f717369c64b90b7e80fbb9c1a9997",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_4fb7436f92ee48cdac83c344904dcccf",
      "value": "Truncating\u2007train\u2007dataset\u2007(num_proc=2):\u2007100%"
     }
    },
    "01825c2a354d40799555a990ba73996b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb7a01cb8f3848eb94734efa0aee1e61",
      "max": 112754,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4dc4406ad32e4abf8a491fb59006b491",
      "value": 112754
     }
    },
    "8f2fd22e31f4485ba97f2fe38e61c9f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_87334ad1ff3f4281977968469e37183d",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_ea5cc23294cc474e93840332d604971a",
      "value": "\u2007112754/112754\u2007[01:39&lt;00:00,\u20071243.39\u2007examples/s]"
     }
    },
    "1921af3669174ac087763cdc506ee76d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "269f717369c64b90b7e80fbb9c1a9997": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fb7436f92ee48cdac83c344904dcccf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eb7a01cb8f3848eb94734efa0aee1e61": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4dc4406ad32e4abf8a491fb59006b491": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "87334ad1ff3f4281977968469e37183d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea5cc23294cc474e93840332d604971a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3623ca82f6ef49c285ffde06c2265d47": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f12f63657f344aaaae37d0b926ef2a67",
       "IPY_MODEL_174598c6bb8946bfb288980ecfb41043",
       "IPY_MODEL_e57a6673a2b24f61a86952868d19398b"
      ],
      "layout": "IPY_MODEL_03aa9cc5cce4488dbf4d82d62e72af16"
     }
    },
    "f12f63657f344aaaae37d0b926ef2a67": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c29f4e94b2647f3abadfacaa590e2bb",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_70701b3922a84f0eaaa8eaffeb9787d3",
      "value": "Map:\u2007100%"
     }
    },
    "174598c6bb8946bfb288980ecfb41043": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c2099110ef84a89a8eac9b4ac02106a",
      "max": 967,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5c38cfd5e75f4ab98d1613f95fcf8733",
      "value": 967
     }
    },
    "e57a6673a2b24f61a86952868d19398b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52a792e911f649b9b051ce1578832686",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_2b09ff9587ab4ff5a07a8e46bb49b413",
      "value": "\u2007967/967\u2007[00:00&lt;00:00,\u200717313.12\u2007examples/s]"
     }
    },
    "03aa9cc5cce4488dbf4d82d62e72af16": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c29f4e94b2647f3abadfacaa590e2bb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70701b3922a84f0eaaa8eaffeb9787d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2c2099110ef84a89a8eac9b4ac02106a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c38cfd5e75f4ab98d1613f95fcf8733": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "52a792e911f649b9b051ce1578832686": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b09ff9587ab4ff5a07a8e46bb49b413": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}